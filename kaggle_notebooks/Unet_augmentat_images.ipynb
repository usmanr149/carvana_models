{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import zipfile\nfrom skimage.util import random_noise","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = '../input/carvana-image-masking-challenge/'\n# Will unzip the files so that you can see them..\nwith zipfile.ZipFile(DATA_PATH + \"train_masks.csv.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Will unzip the files so that you can see them..\nwith zipfile.ZipFile(DATA_PATH + \"train.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Will unzip the files so that you can see them..\nwith zipfile.ZipFile(DATA_PATH + \"train_masks.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os \nfrom glob import glob\n\nINPUT_PATH = '.'\nDATA_PATH = INPUT_PATH\nTRAIN_DATA = os.path.join(DATA_PATH, \"train\")\nTRAIN_MASKS_DATA = os.path.join(DATA_PATH, \"train_masks\")\n# TEST_DATA = os.path.join(DATA_PATH, \"test\")\n# TRAIN_MASKS_CSV_FILEPATH = os.path.join(DATA_PATH, \"train_masks.csv\")\n# METADATA_CSV_FILEPATH = os.path.join(DATA_PATH, \"metadata.csv\")\n\n# TRAIN_MASKS_CSV = pd.read_csv(TRAIN_MASKS_CSV_FILEPATH)\n# METADATA_CSV = pd.read_csv(METADATA_CSV_FILEPATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# random module is imported \nimport random\n\nrandom.seed(33)\n\ntrain_files = np.array(glob(os.path.join(TRAIN_DATA, \"*.jpg\")))\ntrain_ids = np.array([s[len(TRAIN_DATA)+1:-4] for s in train_files])\n\nsize_ = len(train_ids)\nindices = np.random.permutation(size_)\n\n# train_indices = indices[:int(0.9*size_)]\ntrain_indices = indices[:500]\n# test_indices = indices[int(0.9*size_):]\ntest_indices = indices[500:700]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_files, train_ids, test_files, test_ids = train_files[train_indices], train_ids[train_indices], train_files[test_indices], train_ids[test_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_filename(image_id, image_type):\n    check_dir = False\n    if \"Train\" == image_type:\n        ext = 'jpg'\n        data_path = TRAIN_DATA\n        suffix = ''\n    elif \"Train_mask\" in image_type:\n        ext = 'gif'\n        data_path = TRAIN_MASKS_DATA\n        suffix = '_mask'\n    elif \"Test\" in image_type:\n        ext = 'jpg'\n        data_path = TEST_DATA\n        suffix = ''\n    else:\n        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n\n    if check_dir and not os.path.exists(data_path):\n        os.makedirs(data_path)\n\n    return os.path.join(data_path, \"{}{}.{}\".format(image_id, suffix, ext))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_size = (864//2,576//2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\n\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\n# from keras.preprocessing.image import ImageDataGenerator\nfrom keras_preprocessing.image import flip_axis, ImageDataGenerator\n\nimg_gen = ImageDataGenerator()\n\nimport tensorflow as tf\nfrom scipy import ndimage, misc\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_flip(img, mask, u=0.5):\n    if np.random.random() < u:\n        img = flip_axis(img, 1)\n        mask = flip_axis(mask, 1)\n    return img, mask\n\ndef rotate(x, theta, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest', cval=0.):\n    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                [np.sin(theta), np.cos(theta), 0],\n                                [0, 0, 1]])\n    h, w = x.shape[row_axis], x.shape[col_axis]\n    transform_matrix = img_gen.transform_matrix_offset_center(rotation_matrix, h, w)\n    x = img_gen.apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n    return x\n\ndef random_rotate(img, mask, rotate_limit=(-20, 20), u=0.5):\n    if np.random.random() < u:\n        theta = np.pi / 180 * np.random.uniform(rotate_limit[0], rotate_limit[1])\n        img = ndimage.rotate(img, theta, reshape=False)\n        mask = ndimage.rotate(mask, theta, reshape=False)\n\n#         img = rotate(img, theta)\n#         mask = rotate(mask, theta)\n    return img, mask\n\ndef random_shift(img, mask, w_limit=(-0.1, 0.1), h_limit=(-0.1, 0.1), u=0.5):\n    if np.random.random() < u:\n        wshift = np.random.uniform(w_limit[0], w_limit[1])\n        hshift = np.random.uniform(h_limit[0], h_limit[1])\n                \n        img = ndimage.shift(img, (wshift, hshift, 0))\n        mask = ndimage.shift(mask, (wshift, hshift))\n#         img = shift(img, wshift, hshift)\n#         mask = shift(mask, wshift, hshift)\n    return img, mask\n\ndef shift(x, wshift, hshift, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest', cval=0.):\n    h, w = x.shape[row_axis], x.shape[col_axis]\n    tx = hshift * h\n    ty = wshift * w\n    translation_matrix = np.array([[1, 0, tx],\n                                   [0, 1, ty],\n                                   [0, 0, 1]])\n    transform_matrix = translation_matrix  # no need to do offset\n    x = img_gen.apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n    return x\n\ndef zoom(x, zx, zy, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest', cval=0.):\n    zoom_matrix = np.array([[zx, 0, 0],\n                            [0, zy, 0],\n                            [0, 0, 1]])\n    h, w = x.shape[row_axis], x.shape[col_axis]\n    transform_matrix = img_gen.transform_matrix_offset_center(zoom_matrix, h, w)\n    x = img_gen.apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n    return x\n\ndef random_zoom(img, mask, zoom_range=(0.8, 1), u=0.5):\n    if np.random.random() < u:\n        zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n        img = zoom(img, zx, zy)\n        mask = zoom(mask, zx, zy)\n    return img, mask\n\ndef shear(x, shear, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest', cval=0.):\n    shear_matrix = np.array([[1, -np.sin(shear), 0],\n                             [0, np.cos(shear), 0],\n                             [0, 0, 1]])\n    h, w = x.shape[row_axis], x.shape[col_axis]\n    transform_matrix = img_gen.transform_matrix_offset_center(shear_matrix, h, w)\n    x = img_gen.apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n    return x\n\ndef random_shear(img, mask, intensity_range=(-0.5, 0.5), u=0.5):\n    if np.random.random() < u:\n        sh = np.random.uniform(-intensity_range[0], intensity_range[1])\n        img = shear(img, sh)\n        mask = shear(mask, sh)\n    return img, mask\n\ndef random_channel_shift(x, limit, channel_axis=2):\n    x = np.rollaxis(x, channel_axis, 0)\n    min_x, max_x = np.min(x), np.max(x)\n    channel_images = [np.clip(x_ch + np.random.uniform(-limit, limit), min_x, max_x) for x_ch in x]\n    x = np.stack(channel_images, axis=0)\n    x = np.rollaxis(x, 0, channel_axis + 1)\n    return x\n\ndef random_gray(img, u=0.5):\n    if np.random.random() < u:\n        coef = np.array([[[0.114, 0.587, 0.299]]])  # rgb to gray (YCbCr)\n        gray = np.sum(img * coef, axis=2)\n        img = np.dstack((gray, gray, gray))\n    return img\n\ndef random_contrast(img, limit=(-0.3, 0.3), u=0.5):\n    if np.random.random() < u:\n        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n        coef = np.array([[[0.114, 0.587, 0.299]]])  # rgb to gray (YCbCr)\n        gray = img * coef\n        gray = (3.0 * (1.0 - alpha) / gray.size) * np.sum(gray)\n        img = alpha * img + gray\n        img = np.clip(img, 0., 1.)\n    return img\n\ndef random_brightness(img, limit=(-0.3, 0.3), u=0.5):\n    if np.random.random() < u:\n        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n        img = alpha * img\n        img = np.clip(img, 0., 1.)\n    return img\n\ndef random_saturation(img, limit=(-0.3, 0.3), u=0.5):\n    if np.random.random() < u:\n        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n        coef = np.array([[[0.114, 0.587, 0.299]]])\n        gray = img * coef\n        gray = np.sum(gray, axis=2, keepdims=True)\n        img = alpha * img + (1. - alpha) * gray\n        img = np.clip(img, 0., 1.)\n    return img\n\ndef random_augmentation(img, mask):\n    img = random_channel_shift(img, limit=0.05)\n    img = random_brightness(img, (-0.5, 0.5), 0.5)\n    img = random_contrast(img, (-0.5, 0.5), 0.5)\n    img = random_saturation(img, (-0.5, 0.5), 0.5)\n    img = random_gray(img, 0.2)\n    img, mask = random_rotate(img, mask, (-20, 20), 0.5)\n#     img, mask = random_shear(img, mask, (-0.3, 0.3), 0.2)\n    img, mask = random_flip(img, mask, 0.3)\n    img, mask = random_shift(img, mask, (-20, 20), (-20, 20), 0.3)\n#     img, mask = random_zoom(img, mask, (0.8, 1), 0.3)\n    return img, mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nfrom PIL import Image\n\ndef mean_shift(input_img):\n    # Shape of original image\n    originShape = input_img.shape\n    # Converting image into array of dimension [nb of pixels in originImage, 3]\n    # based on r g b intensities    \n    flatImg=np.reshape(input_img, [-1, 3])\n\n\n    # Estimate bandwidth for meanshift algorithm    \n    bandwidth = estimate_bandwidth(flatImg, quantile=0.1, n_samples=50)    \n    ms = MeanShift(bandwidth = bandwidth, bin_seeding=True)\n\n    # Performing meanshift on flatImg    \n    ms.fit(flatImg)\n\n    # (r,g,b) vectors corresponding to the different clusters after meanshift    \n    labels=ms.labels_\n    \n    # Remaining colors after meanshift    \n    cluster_centers = ms.cluster_centers_    \n\n    # Finding and diplaying the number of clusters    \n    labels_unique = np.unique(labels)    \n    n_clusters_ = len(labels_unique)\n    \n    return np.reshape(labels, (*input_img.shape[:2], 1))\n\n\ndef get_image_data(image_id, image_type, **kwargs):\n    if 'mask' in image_type:\n        img = _get_image_data_pil(image_id, image_type, **kwargs)\n    else:\n        img = _get_image_data_opencv(image_id, image_type, **kwargs)\n    return img\n\ndef _get_image_data_opencv(image_id, image_type, **kwargs):\n    fname = get_filename(image_id, image_type)\n    img = cv2.imread(fname)\n    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    if True:\n        img = cv2.resize(img, image_size)\n        # Add salt-and-pepper noise to the image.\n    return img/np.max(img)\n\n\ndef _get_image_data_pil(image_id, image_type, return_exif_md=False, return_shape_only=False):\n    fname = get_filename(image_id, image_type)\n    try:\n        img_pil = Image.open(fname)\n    except Exception as e:\n        assert False, \"Failed to read image : %s, %s. Error message: %s\" % (image_id, image_type, e)\n\n    if return_shape_only:\n        return img_pil.size[::-1] + (len(img_pil.getbands()),)\n    if True:\n#         img_pil = img_pil.resize((388, 388))\n        img_pil = img_pil.resize(image_size)\n    img = np.asarray(img_pil)\n    assert isinstance(img, np.ndarray), \"Open image is not an ndarray. Image id/type : %s, %s\" % (image_id, image_type)\n    if not return_exif_md:\n        return img\n    else:\n        return img, img_pil._getexif()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pylab as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, batch_size=32, dim=(32,32,32), n_channels=1, \n                 shuffle=True, image_type='Train', mask_image_type='Train_mask'):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n        self.image_type = image_type\n        self.mask_image_type = mask_image_type\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n    \n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n        # cv2 recevrses height and width\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n#         X = np.empty((self.batch_size, *self.dim[::-1], self.n_channels))\n#         y = np.empty((self.batch_size, *self.dim[::-1]))\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size, *self.dim))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            img, mask = get_image_data(ID, self.image_type), get_image_data(ID, self.mask_image_type)\n            img, mask = random_augmentation(img, mask)\n            X[i,] = np.rot90(img)\n            y[i,] = np.rot90(mask)\n        \n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameters\nparams = {'dim': image_size,\n          'batch_size': 2,\n          'n_channels': 3,\n          'shuffle': True}\n\n# Generators\ntraining_generator = DataGenerator(train_ids, **params)\nvalidation_generator = DataGenerator(test_ids, **params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unet(input_img):\n    # padding = 0 , stride = 1\n    # input image = 576*576\n    c1 = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(input_img) #576*576\n    c2 = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(c1) # 576*576\n    mp1 = MaxPool2D(pool_size=(2,2))(c2) # 288*288\n    c3 = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(mp1) # 288*288\n    c4 = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(c3) # 288*288\n    mp2 = MaxPool2D(pool_size=(2,2))(c4) # 144*144\n    c5 = Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same')(mp2) # 144*144\n    c6 = Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same')(c5) # 144*144\n    mp3 = MaxPool2D(pool_size=(2,2))(c6) # 72*72\n    c7 = Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same')(mp3) # 72*72\n    c8 = Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same')(c7) # 72*72\n    mp4 = MaxPool2D(pool_size=(2,2))(c8) # 36*36\n    dr1 = Dropout(rate=0.3)(mp4)\n    c9 = Conv2D(filters=1024, kernel_size=(3,3), activation='relu', padding='same')(dr1) # 36*36\n    c10 = Conv2D(filters=1024, kernel_size=(3,3), activation='relu', padding='same')(c9) # 36*36\n    \n    #upsampling followed by a 2x2 convolution\n#     up1 = UpSampling2D(size=(2,2))(c10) # 56*56\n    # up convolve\n    up1 = Conv2DTranspose(512, (2,2), strides=(2,2), padding='valid', activation='relu')(c10)    # 72*72 concatenate c8\n    merge1 = concatenate([c8, up1]) # 72*72\n    c11 = Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same')(merge1) # 72*72\n    c12 = Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same')(c11) # 72*72\n#     up2 = UpSampling2D(size=(2,2))(c12) # 104*104\n    up2 = Conv2DTranspose(256, (2,2), strides=(2,2), padding='valid', activation='relu')(c12) # 144*144\n\n    # concatenate c6\n    merge2 = concatenate([c6, up2]) # 144*144\n    c13 = Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same')(merge2) # 144*144\n    c14 = Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same')(c13) # 144*144\n    up3 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='valid', activation='relu')(c14) # 288*288\n#     # concatenate c4\n    merge3 = concatenate([c4, up3])\n    c15 = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(merge3) # 288*288\n    c16 = Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(c15) # 288*288\n    up4 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='valid', activation='relu')(c16) # 576*576\n#     # conctenate c2\n    merge4 = concatenate([c2, up4]) # 576*576\n    c17 = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(merge4) # 576*576\n    c18 = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(c17) # 576*576\n    # filters here need to be the nu,ber of classes\n    c19 = Conv2D(filters=1, kernel_size=(1,1), padding='same', activation='sigmoid')(c18) # 576*576\n    \n    return c19","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_img = Input(shape = (*params['dim'], params['n_channels']))\n\ndef dice_loss(y_true, y_pred):\n    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n    denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n\n    return (numerator + 1) / (denominator + 1)\n\nautoencoder = Model(input_img, unet(input_img))\nautoencoder.compile(loss=keras.losses.binary_crossentropy, metrics=[dice_loss, keras.losses.binary_crossentropy], optimizer='adam')\n# autoencoder.compile(loss=dice_loss, metrics=[dice_loss, keras.losses.binary_crossentropy], optimizer='adam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder_train = autoencoder.fit_generator(generator=training_generator,\n                    validation_data=validation_generator,\n                    use_multiprocessing=True,\n                    workers=1, epochs=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = autoencoder_train.history['loss']\nval_loss = autoencoder_train.history['val_loss']\nepochs_ = range(30)\nplt.figure()\nplt.plot(epochs_, loss, 'bo', label='Training loss')\nplt.plot(epochs_, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs = validation_generator.__getitem__(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_images = imgs[0]\ntesting_images = imgs[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(training_images[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(testing_images[1], cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_images[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = autoencoder.predict(training_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(pred[1].reshape(432,288), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(pred[0].reshape(432,288), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder.save('unet_30_iter_binary_loss_432_288_deep.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_loss(y_true, y_pred):\n    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n    denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n\n    return (numerator + 1) / (denominator + 1)\n\ndependencies = {\n    'dice_loss': dice_loss\n}\n\n# load model\nmodel = load_model('../input/unetmodel/unet_5_iter_binary_loss_deep.h5', custom_objects=dependencies)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs = get_image_data(train_ids[203], 'Train')\n\n# X = np.empty((1,*image_size[::-1], 3))\n\nX = np.empty((1,*image_size, 3))\n\nX[0] = np.rot90(imgs)\n\n# imgs = np.rot90(imgs)\n# plt.imshow(np.rot90(imgs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(imgs.shape)\nprint(X[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(pred[0].reshape(864,576), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(pred[0].reshape(388,388), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ae_2 = model.fit_generator(generator=training_generator,\n                    validation_data=validation_generator,\n                    use_multiprocessing=True,\n                    workers=1, epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(training_images)\nplt.imshow(pred[0].reshape(388,388), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('unet_multi_iter_binary_loss.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}